# Back-Propagation
![BackPropagation](https://user-images.githubusercontent.com/52197131/212425360-e165e1da-9b72-4f93-8233-d66e8e7688e1.png)

In the above neural network, we have 3 layers.

  1. Input layer
  2. Hidden layer
  3. Output layer
 
 w1,w2,w3,w4,w5,w6,w7,w8 are the weights.
 
 In this network we have two outputs. So we are having two errors E1 and E2.
 
 E1 and E2 are L2 Error.
 
 We use sigmoid function in hidden layer and output layer  for introducing non linearity.
 
 In the excel sheet, each weight , output, error,error gradient with respect to each weight is calculated.
 
 For each epoch weight is modified such that the total error decreases
 
 New weights values are calculated from the previous weight value , learning rate and error gradient.
 
 
 
 
 
 Graph with learning rate 0.1
 
![image](https://user-images.githubusercontent.com/52197131/212430489-c646cd0e-8661-49c4-8dcb-bf9d9067ca84.png)

 
 
 Graph with learning rate 0.01
 
 ![image](https://user-images.githubusercontent.com/52197131/212430568-937d19bf-b937-43ee-8bc6-8eca7c0b72db.png)

 
 
 
 Graph with learning rate 0.001
 

![image](https://user-images.githubusercontent.com/52197131/212430612-1b423a6f-ecd5-4e89-bfdb-0475e0f22fba.png)




 
 


